{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1744889</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1395430</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1205593</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1488844</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1447354</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id  user_id  rating\n",
       "0         8  1744889     1.0\n",
       "1         8  1395430     2.0\n",
       "2         8  1205593     4.0\n",
       "3         8  1488844     4.0\n",
       "4         8  1447354     1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "\n",
    "##############################################################################\n",
    "#      MOVIE RECOMMENDATION SYSTEM - SMALL SUBSET OF NETFLIX PRIZE DATE      #\n",
    "##############################################################################\n",
    "\n",
    "# start by putting training and testing netflix data into a dataframe\n",
    "cols = ['movie_id', 'user_id', 'rating']\n",
    "traindf = pd.read_csv('netflix_subset/TrainingRatings.txt', names=cols)\n",
    "testdf = pd.read_csv('netflix_subset/TestingRatings.txt', names=cols)\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df:  (3255352, 3) | test df:  (100478, 3)\n",
      "\n",
      "number of users:  28978 | number of movies:  1821\n"
     ]
    }
   ],
   "source": [
    "# print the size of the total dataset, first\n",
    "print('train df: ', traindf.shape, '| test df: ', testdf.shape)\n",
    "# then let's look at the the number of users and the number of movies\n",
    "num_users = traindf.user_id.unique().shape[0]\n",
    "num_movies = traindf.movie_id.unique().shape[0]\n",
    "\n",
    "print('\\nnumber of users: ', num_users, '| number of movies: ', num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>3290</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>The Godfather, Part II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id    year                   title\n",
       "3289      3290  1974.0  The Godfather, Part II"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv \n",
    "\n",
    "titlecols = ['movie_id', 'year', 'title']\n",
    "\n",
    "# let's make a dictionary to map movie-ids to their titles\n",
    "\n",
    "# it's converting the year to float to deal w NaN; not going to worry about it bc i don't need the year anyway\n",
    "# doing this to deal with commas within the movie titles - 'The Godfather, Part II' \n",
    "with open(\"netflix_subset/movietitles.csv\", 'rt', encoding='latin1') as infile, open('netflix_subset/formatted_titles.csv', 'wt') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    for line in reader:\n",
    "        newline = line[:2] + [','.join(line[2:])]\n",
    "        writer.writerow(newline)\n",
    "\n",
    "\n",
    "titles = pd.read_csv('netflix_subset/formatted_titles.csv', names=titlecols, encoding='latin1')\n",
    "\n",
    "tdict = pd.Series(titles.title.values, index=titles.movie_id).to_dict()\n",
    "\n",
    "titles.loc[titles.movie_id == 3290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# both userIDs and movieIDs increase by random increments so putting them into sorted lists for the user-item matrix\n",
    "userIDs = sorted(traindf.user_id.unique())\n",
    "movieIDs = sorted(traindf.movie_id.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# before getting into the collab filtering, let's find the top rated movies across all users\n",
    "# using the bayesian avg\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "reviews = defaultdict(list)\n",
    "# get a list of all reviews for a certain movie-id and add it to a dictionary\n",
    "def get_reviews(mov_id, df, revdict):\n",
    "    revdict[mov_id] = df.loc[df['movie_id'] == mov_id, 'rating']\n",
    "\n",
    "# function to fill the dictionary       \n",
    "def create_rev_dict(id_list, df, revdict):\n",
    "    for mid in id_list:\n",
    "        get_reviews(mid, df, revdict)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########################â€¹########################\n",
    "\n",
    "create_rev_dict(movieIDs, traindf, reviews)\n",
    "\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of netflix reviews per movie:  1787.673\n",
      "average rating for netflix movies:  3.058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# in order to get the bayes avg we need to compute priors \n",
    "\n",
    "# returns the movie-id, avg-rating(1-5), and the number of ratings\n",
    "def calc_avgs(id_list, revdict):\n",
    "    for m in id_list:\n",
    "        avg = sum(revdict[m]) / float(len(revdict[m]))\n",
    "        yield (m, avg, len(revdict[m]))\n",
    "\n",
    "        \n",
    "# put them into a df so we can easily compute the mean()\n",
    "averages = pd.DataFrame(calc_avgs(movieIDs, reviews), columns=['m_id', 'avg_rating', 'num_reviews'])\n",
    "\n",
    "# add the movie titles to df \n",
    "averages['mtitle'] = averages['m_id'].map(tdict)\n",
    "# we need the avg number of reviewers for each movie (c)\n",
    "print(\"average number of netflix reviews per movie: \", round(averages.num_reviews.mean(), 3))\n",
    "# and the mean of all the movies' avg ratings\n",
    "print(\"average rating for netflix movies: \", round(averages.avg_rating.mean(), 3))\n",
    "\n",
    "# this gives a naive approach to ranking the movies by their avg rating bc it doesn't take number of reviews into account\n",
    "# averages.sort_values(['avg_rating'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################  TOP RATED NETFLIX MOVIES - BAYESIAN AVG ############################\n",
      "4.348 average rating (20691 reviews) The Godfather\n",
      "4.235 average rating (21209 reviews) The Incredibles\n",
      "4.215 average rating (10430 reviews) The Sopranos: Season 1\n",
      "4.214 average rating (17292 reviews) The Godfather, Part II\n",
      "4.189 average rating (9579 reviews) The Sopranos: Season 3\n",
      "4.052 average rating (13771 reviews) Aladdin: Platinum Edition\n",
      "4.028 average rating (15086 reviews) Million Dollar Baby\n",
      "4.024 average rating (23005 reviews) Seven\n",
      "4.013 average rating (5941 reviews) Six Feet Under: Season 2\n",
      "4.002 average rating (16170 reviews) Alien: Collector's Edition\n"
     ]
    }
   ],
   "source": [
    "# where c are priors - c: avg num reviews/movie, m: avg rating\n",
    "def bayes_avg(c, m, id_list, revdict):\n",
    "    for m_id in id_list:\n",
    "        avg = ((c * m) + sum(revdict[m_id])) / float(c + len(revdict[m_id]))\n",
    "        yield (m_id, avg, len(revdict[m_id]))\n",
    "\n",
    "def bayes_top_n(n, idlist, revdict, c, m):\n",
    "    return heapq.nlargest(n, bayes_avg(c, m, idlist, revdict), key=itemgetter(1))\n",
    "\n",
    "\n",
    "# bayesian avg to compute most popular movies on netflix \n",
    "print ('########################  TOP RATED NETFLIX MOVIES - BAYESIAN AVG ############################')\n",
    "for movid, avg, num in bayes_top_n(10, idlist=movieIDs, revdict=reviews, c=1787, m=3):\n",
    "    print(\"%0.3f average rating (%i reviews) %s\" % (avg, num, tdict[movid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# careful !! don't run this one again (it takes a long time)\n",
    "\n",
    "# # create a user-item matrix so we can compute cosine similarities\n",
    "traintrix = np.zeros((num_users, num_movies))\n",
    "\n",
    "# # for each row, find the user/movie ID's index in its respective list and add it to those indices in the u-i matrix\n",
    "\n",
    "\n",
    "for row in traindf.itertuples():\n",
    "    traintrix[userIDs.index(row[2]), movieIDs.index(row[1])] = row[3]\n",
    "    \n",
    "# # create user-item matrix with test dataset\n",
    "testtrix = np.zeros((num_users, num_movies))\n",
    "\n",
    "for row in testdf.itertuples():\n",
    "    testtrix[userIDs.index(row[2]), movieIDs.index(row[1])] = row[3]\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28978, 1821)\n",
      "[ 5.  4.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33639</th>\n",
       "      <td>185</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82974</th>\n",
       "      <td>636</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129845</th>\n",
       "      <td>1046</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        movie_id  user_id  rating\n",
       "1429           8        7     5.0\n",
       "8911          28        7     4.0\n",
       "33639        185        7     4.0\n",
       "82974        636        7     4.0\n",
       "129845      1046        7     3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## testing ##########\n",
    "print(traintrix.shape)\n",
    "# the first ten entries by the first user (corresponding to 10 smallest movie-ids) - 0 for null values\n",
    "print(traintrix[0,:10])\n",
    "# to see all of the ratings by user 7 -- 8 & 28 are the first two movie-ids\n",
    "traindf.loc[traindf['user_id']==7].head()\n",
    "\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute cosine similarity between users (or items)\n",
    "\n",
    "def compute_sim(ui_matrix, kind='user', epsilon=1e-9):\n",
    "    if kind=='user':\n",
    "        sim = ui_matrix.dot(ui_matrix.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ui_matrix.T.dot(ui_matrix) + epsilon\n",
    "    norms = np.array([np.sqrt(np.diagonal(sim))])\n",
    "    return (sim / norms / norms.T)\n",
    "\n",
    "user_similarity = compute_sim(traintrix, kind='user')\n",
    "#print(user_similarity[:4, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1min 19s per loop\n"
     ]
    }
   ],
   "source": [
    "# now we make predictions! \n",
    "# let's see the difference between normalizing by the mean or not(predict2)\n",
    "def predict(ui_matrix, similarity, kind='user'):\n",
    "    if kind=='user':\n",
    "        mean_user_rating = ui_matrix.mean(axis=1)\n",
    "        ratings_diff = (ui_matrix - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind=='item':\n",
    "        pred = ui_matrix.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred\n",
    "\n",
    "%timeit predict(traintrix, user_similarity, kind='user')\n",
    "# incredibly slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1min 12s per loop\n"
     ]
    }
   ],
   "source": [
    "def predict2(ui_matrix, similarity, kind='user'):\n",
    "    if kind=='user':\n",
    "        return similarity.dot(ui_matrix) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind=='item':\n",
    "        return ui_matrix.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    \n",
    "%timeit predict2(traintrix, user_similarity, kind='user')\n",
    "# only a lil faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usr_pred = predict(traintrix, user_similarity, kind='user')\n",
    "usr_prediction2 = predict2(traintrix, user_similarity, kind='user')\n",
    "\n",
    "#print(rmse(usrpred2, testtrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error w Normalization:  2.512 | Root Mean Squared Error w.o Normalization:  2.545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# now let's evaluate accuracy\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "\n",
    "print('Root Mean Squared Error w Normalization: ', round(rmse(usr_pred, testtrix), 3), '| Root Mean Squared Error w.o Normalization: ', round(rmse(usr_prediction2, testtrix), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's see how it works for item-based collaborative filtering\n",
    "\n",
    "item_similarity = compute_sim(traintrix, kind='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.78 s per loop\n"
     ]
    }
   ],
   "source": [
    "item_pred = predict(traintrix, item_similarity, kind='item')\n",
    "%timeit predict(traintrix, item_similarity, kind='item')\n",
    "# a lot faster, predictably (way fewer items than users) \n",
    "# 'item' is the same in both predict() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (item-based):  2.967\n"
     ]
    }
   ],
   "source": [
    "print('Root Mean Squared Error (item-based): ', round(rmse(item_pred, testtrix), 3))\n",
    "# we lose a bit of accuracy but there's obviously a time trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
