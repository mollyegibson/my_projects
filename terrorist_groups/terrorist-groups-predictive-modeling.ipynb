{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170350, 22) \n",
      "\n",
      "Features:\n",
      " ['year', 'region', 'crit1', 'crit2', 'crit3', 'doubtterr', 'multiple', 'success', 'suicide', 'attacktype1', 'attacktype2', 'attacktype3', 'targtype1', 'natlty1', 'groupname', 'nperps', 'claimed', 'competingclaims', 'weaptype1', 'weapsubtype1', 'nkill', 'hostages']\n"
     ]
    }
   ],
   "source": [
    "# Coding challenge for fellowship.AI\n",
    "\n",
    "# Molly Gibson - September 12, 2017\n",
    "\n",
    "# data from http://www.start.umd.edu/gtd/contact/ - full GTD dataset\n",
    "# data downloaded in .xlsx format, so I converted to familiar csv:\n",
    "# $ pip install csvkit\n",
    "# $ in2csv datasets/globalterrorismdb_0617dist.xlsx > globalterrorism_db.csv\n",
    "\n",
    "# Goal of the challenge: use attack type, weapons used, description of the attack, etc. to build a model that\n",
    "# can predict what group may have been responsible for an incident\n",
    "\n",
    "# first, install basic dependencies: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# then upload the GTD data\n",
    "df = pd.read_csv('globalterrorism_db.csv', encoding='ISO-8859-1', usecols=[1,9,19,20,21,22,25,26,27,28,30,\n",
    "                                                                                  32,34,40,58,69,71,80,81,83,98,109])\n",
    "\n",
    "print(df.shape, '\\n')\n",
    "\n",
    "# rename a few columns for readability:\n",
    "df = df.rename(columns={'iyear':'year', 'gname':'groupname','compclaim':'competingclaims', 'ishostkid':'hostages'})\n",
    "\n",
    "\n",
    "# get the names of each column along w index so we can pick which features to use\n",
    "# for idx, col in enumerate(df.columns):\n",
    "#     print(idx, col)\n",
    "# don't need after we add usecols=[] to pd.read_csv, but might want to go back to use diff features\n",
    "\n",
    "# print datatypes of each column\n",
    "#print(df.dtypes)\n",
    "print('Features:\\n',list(df.columns))\n",
    "\n",
    "# choosing features: notes to self\n",
    "# for target types and nationalities, only going to use the first col\n",
    "# only taking first col of claimed, but also using compclaim (boolean, competing claims from two groups)\n",
    "# weaptype and weapsubtype, only using first col\n",
    "\n",
    "\n",
    "# now we need to deal with NA values, which exist in the float64 dtype columns\n",
    "# 9:unknown for attack types\n",
    "df.attacktype2 = df.attacktype2.fillna(9).astype(int)\n",
    "df.attacktype3 = df.attacktype3.fillna(9).astype(int)\n",
    "\n",
    "df.natlty1 = df.natlty1.fillna(-9).astype(int)\n",
    "\n",
    "# changing NaN to -9 \n",
    "df.nperps = df.nperps.fillna(-99).astype(int)\n",
    "df.claimed, df.competingclaims = df.claimed.fillna(0).astype(int), df.competingclaims.fillna(-9).astype(int)\n",
    "# 13:unknown for weapon types\n",
    "df.weaptype1, df.weapsubtype1 = df.weaptype1.fillna(13).astype(int), df.weapsubtype1.fillna(-9).astype(int)\n",
    "df.nkill, df.hostages = df.nkill.fillna(-9).astype(int), df.hostages.fillna(-9).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains terrorist attacks from 1970 to 2016\n"
     ]
    }
   ],
   "source": [
    "print('This dataset contains terrorist attacks from', df.year.min(), 'to', df.year.max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of terrorist groups in the database:  3454\n",
      "number of groups we are considering:  870\n",
      "(166204, 22)\n"
     ]
    }
   ],
   "source": [
    "# Now let's count the number of recorded attacks by each group\n",
    "# we will probably only want to consider groups with > n attacks\n",
    "counts = df[['region','groupname']].groupby(['region','groupname']).size().reset_index(name='count') \\\n",
    "                            .sort_values(['count'],ascending=False)\n",
    "\n",
    "print('number of terrorist groups in the database: ', len(counts.groupname.unique()))\n",
    "\n",
    "# only include groups that are responsibile for 5+ attacks\n",
    "counts = counts[counts['count'] > 4]\n",
    "\n",
    "print('number of groups we are considering: ', len(counts.groupname.unique()))\n",
    "\n",
    "# then alter dataframe to only include rows in which groupname appears 5+ times\n",
    "df = df[df.groupname.isin(counts.groupname)]\n",
    "print(df.shape)\n",
    "\n",
    "# dict of each region name corresponding with its number\n",
    "regdict = {'1':'North America', '2':'Central America & Caribbean', '3':'South America', '4':'East Asia',\n",
    "          '5':'Southeast Asia', '6':'South Asia', '7':'Central Asia', '8':'Western Europe', '9':'Eastern Europe',\n",
    "          '10':'Middle East & North Africa', '11':'Sub-Saharan Africa', '12':'Australia & Oceania'}\n",
    "\n",
    "# separate each region into its own dataframe, stored in dictionary\n",
    "# DFs - main dataframe divided into regions\n",
    "# countsbyreg - frequency of groups in each region\n",
    "DFs = {}\n",
    "countsbyreg = {}\n",
    "for reg in counts.region:\n",
    "    name = regdict[str(reg)]\n",
    "    DFs[name] = df[df.region==reg]\n",
    "    countsbyreg[name] = counts[counts.region==reg]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Middle East & North Africa \n",
      "\n",
      " 170  groups with 5+ attacks \n",
      " 45766  incidents \n",
      "\n",
      " 60.2 % unknown groupnames \n",
      "\n",
      "       region                                    groupname  count\n",
      "3484      10                                      Unknown  27550\n",
      "3102      10  Islamic State of Iraq and the Levant (ISIL)   4260\n",
      "3184      10               Kurdistan Workers' Party (PKK)   1980\n",
      "3306      10                                 Palestinians   1104\n",
      "2854      10     Al-Qaida in the Arabian Peninsula (AQAP)    972 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "South Asia \n",
      "\n",
      " 195  groups with 5+ attacks \n",
      " 40927  incidents \n",
      "\n",
      " 50.11 % unknown groupnames \n",
      "\n",
      "       region                                       groupname  count\n",
      "1719       6                                         Unknown  20508\n",
      "1642       6                                         Taliban   6574\n",
      "1292       6  Communist Party of India - Maoist (CPI-Maoist)   1766\n",
      "1459       6         Liberation Tigers of Tamil Eelam (LTTE)   1604\n",
      "1479       6                                         Maoists   1419 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Southeast Asia \n",
      "\n",
      " 54  groups with 5+ attacks \n",
      " 11246  incidents \n",
      "\n",
      " 50.7 % unknown groupnames \n",
      "\n",
      "       region                             groupname  count\n",
      "1150       5                               Unknown   5702\n",
      "1097       5               New People's Army (NPA)   2412\n",
      "948        5                Abu Sayyaf Group (ASG)    470\n",
      "1070       5  Moro Islamic Liberation Front (MILF)    363\n",
      "1126       5                           Separatists    326 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sub-Saharan Africa \n",
      "\n",
      " 120  groups with 5+ attacks \n",
      " 14987  incidents \n",
      "\n",
      " 36.47 % unknown groupnames \n",
      "\n",
      "       region                                 groupname  count\n",
      "3950      11                                   Unknown   5466\n",
      "3522      11                                Al-Shabaab   2683\n",
      "3574      11                                Boko Haram   2077\n",
      "3511      11  African National Congress (South Africa)    606\n",
      "3637      11                         Fulani extremists    433 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "South America \n",
      "\n",
      " 80  groups with 5+ attacks \n",
      " 18401  incidents \n",
      "\n",
      " 28.24 % unknown groupnames \n",
      "\n",
      "      region                                      groupname  count\n",
      "843       3                                        Unknown   5197\n",
      "807       3                              Shining Path (SL)   4550\n",
      "782       3  Revolutionary Armed Forces of Colombia (FARC)   2478\n",
      "711       3     National Liberation Army of Colombia (ELN)   1483\n",
      "689       3        Manuel Rodriguez Patriotic Front (FPMR)    830 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Western Europe \n",
      "\n",
      " 178  groups with 5+ attacks \n",
      " 15387  incidents \n",
      "\n",
      " 31.88 % unknown groupnames \n",
      "\n",
      "       region                                  groupname  count\n",
      "2602       8                                    Unknown   4906\n",
      "2216       8                Irish Republican Army (IRA)   2666\n",
      "1962       8        Basque Fatherland and Freedom (ETA)   2022\n",
      "2066       8  Corsican National Liberation Front (FLNC)    639\n",
      "2425       8                      Protestant extremists    333 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Central America & Caribbean \n",
      "\n",
      " 59  groups with 5+ attacks \n",
      " 10121  incidents \n",
      "\n",
      " 36.38 % unknown groupnames \n",
      "\n",
      "      region                                         groupname  count\n",
      "503       2                                           Unknown   3682\n",
      "354       2  Farabundo Marti National Liberation Front (FMLN)   3351\n",
      "417       2                 Nicaraguan Democratic Force (FDN)    894\n",
      "418       2                             Nicaraguan Resistance    231\n",
      "477       2       Sandinista National Liberation Front (FSLN)    209 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Eastern Europe \n",
      "\n",
      " 24  groups with 5+ attacks \n",
      " 4871  incidents \n",
      "\n",
      " 68.63 % unknown groupnames \n",
      "\n",
      "       region                     groupname  count\n",
      "2779       9                       Unknown   3343\n",
      "2686       9     Donetsk People's Republic    614\n",
      "2672       9                Chechen Rebels    322\n",
      "2720       9     Luhansk People's Republic    207\n",
      "2716       9  Kosovo Liberation Army (KLA)     58 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "North America \n",
      "\n",
      " 82  groups with 5+ attacks \n",
      " 3047  incidents \n",
      "\n",
      " 28.82 % unknown groupnames \n",
      "\n",
      "      region                                      groupname  count\n",
      "275       1                                        Unknown    878\n",
      "16        1                       Anti-Abortion extremists    198\n",
      "151       1                            Left-Wing Militants    169\n",
      "108       1  Fuerzas Armadas de Liberacion Nacional (FALN)    120\n",
      "181       1              New World Liberation Front (NWLF)     86 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "East Asia \n",
      "\n",
      " 13  groups with 5+ attacks \n",
      " 719  incidents \n",
      "\n",
      " 64.26 % unknown groupnames \n",
      "\n",
      "      region                                   groupname  count\n",
      "941       4                                     Unknown    462\n",
      "939       4                          Uighur Separatists     85\n",
      "880       4             Chukakuha (Middle Core Faction)     61\n",
      "920       4  Revolutionary Workers' Council (Kakurokyo)     24\n",
      "885       4         East Asia Anti Japanese Armed Front     12 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Central Asia \n",
      "\n",
      " 6  groups with 5+ attacks \n",
      " 500  incidents \n",
      "\n",
      " 88.6 % unknown groupnames \n",
      "\n",
      "       region                                 groupname  count\n",
      "1776       7                                   Unknown    443\n",
      "1770       7  Supporters of Ex-President Gamsakhurdial     10\n",
      "1768       7                South Ossetian Separatists     10\n",
      "1738       7                     Azerbaijan Guerrillas      7\n",
      "1747       7                                    Gunmen      6 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Australia & Oceania \n",
      "\n",
      " 3  groups with 5+ attacks \n",
      " 232  incidents \n",
      "\n",
      " 72.84 % unknown groupnames \n",
      "\n",
      "       region                                  groupname  count\n",
      "4018      12                                    Unknown    169\n",
      "3985      12      Bougainville Revolutionary Army (BRA)     28\n",
      "4001      12  Kanak Socialist National Liberation Front      5 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# to get an idea of the top 5 frequently occuring groupnames in each region\n",
    "# and the number of groups with over 5 attacks in each region \n",
    "for key in countsbyreg:\n",
    "    print(key,'\\n\\n',len(countsbyreg[key]),' groups with 5+ attacks', '\\n', \n",
    "          len(DFs[key]),' incidents', '\\n\\n', \n",
    "          round(float(countsbyreg[key]['count'][countsbyreg[key].groupname=='Unknown'])/float(len(DFs[key]))*100, 2),\n",
    "          '% unknown groupnames', '\\n\\n', countsbyreg[key].head(),'\\n')\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total percentage of attacks by unknown terrorist groups:  47.114\n",
      "(87898, 23)\n"
     ]
    }
   ],
   "source": [
    "# 'Unknown' is the most common groupname in every region\n",
    "print(\"Total percentage of attacks by unknown terrorist groups: \", \n",
    "      round(float(df.groupname[df.groupname=='Unknown'].count() / df.groupname.count())*100,3))\n",
    "\n",
    "# first off, let's see if we can classify unknown vs. known attacks\n",
    "# in order to do so, add a new boolean column to the dataframe\n",
    "df['is_unknown'] = np.where(df.groupname == 'Unknown', True, False)\n",
    "\n",
    "# separate the unlabeled attacks from the labeled ones; can use known attacks to check accuracy of our models but \n",
    "# ultimately the goal is to predict which groups are responsible for the unknown attacks\n",
    "unknown_df = df[df.groupname == 'Unknown']\n",
    "\n",
    "known_df = df[df.groupname != 'Unknown']\n",
    "\n",
    "print(known_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now onto sklearn!\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #, category=DeprecationWarning)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# and create a df for accuracy of our algorithms in each region\n",
    "results = pd.DataFrame(columns=['Region', 'Accuracy'])\n",
    "\n",
    "# and a dictionary to compare different algorithms, holding a df of accuracies for each one   \n",
    "classifier_accuracies = {}\n",
    "classifier_accuracies_lbld = {}\n",
    "\n",
    "\n",
    "# let's divide the dataset into regions \n",
    "training_X = {}\n",
    "training_y = {}\n",
    "testing_X = {}\n",
    "testing_y = {}\n",
    "\n",
    "for key in DFs:\n",
    "    training_X[key], testing_X[key], training_y[key], testing_y[key] = train_test_split(DFs[key].drop('groupname', axis=1),\n",
    "                                                                                       DFs[key].groupname,\n",
    "                                                                                       test_size=0.3, random_state=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors \n",
      "                          Region Accuracy\n",
      "10                 Central Asia   0.8667\n",
      "11          Australia & Oceania   0.7857\n",
      "9                     East Asia   0.7593\n",
      "6   Central America & Caribbean   0.7428\n",
      "0    Middle East & North Africa   0.7168\n",
      "7                Eastern Europe   0.7073\n",
      "2                Southeast Asia   0.6763\n",
      "3            Sub-Saharan Africa   0.6627\n",
      "1                    South Asia   0.6532\n",
      "4                 South America   0.6513\n",
      "5                Western Europe   0.6409\n",
      "8                 North America   0.5464 \n",
      "\n",
      "Decision Tree \n",
      "                          Region Accuracy\n",
      "10                 Central Asia   0.8933\n",
      "11          Australia & Oceania      0.8\n",
      "9                     East Asia   0.7685\n",
      "6   Central America & Caribbean    0.757\n",
      "7                Eastern Europe   0.7189\n",
      "0    Middle East & North Africa   0.7106\n",
      "1                    South Asia   0.6549\n",
      "2                Southeast Asia   0.6405\n",
      "4                 South America   0.6113\n",
      "5                Western Europe   0.5939\n",
      "3            Sub-Saharan Africa   0.5937\n",
      "8                 North America   0.4055 \n",
      "\n",
      "Random Forest \n",
      "                          Region Accuracy\n",
      "10                 Central Asia   0.9067\n",
      "11          Australia & Oceania   0.8429\n",
      "9                     East Asia   0.8241\n",
      "6   Central America & Caribbean   0.8011\n",
      "0    Middle East & North Africa   0.7757\n",
      "7                Eastern Europe   0.7497\n",
      "2                Southeast Asia   0.7377\n",
      "3            Sub-Saharan Africa   0.7367\n",
      "1                    South Asia   0.7204\n",
      "4                 South America   0.7028\n",
      "5                Western Europe   0.6974\n",
      "8                 North America    0.635 \n",
      "\n",
      "Neural Net \n",
      "                          Region Accuracy\n",
      "10                 Central Asia   0.8867\n",
      "7                Eastern Europe   0.6963\n",
      "11          Australia & Oceania   0.6857\n",
      "6   Central America & Caribbean   0.6562\n",
      "2                Southeast Asia   0.5522\n",
      "9                     East Asia   0.5278\n",
      "3            Sub-Saharan Africa   0.5092\n",
      "5                Western Europe   0.5062\n",
      "1                    South Asia   0.4891\n",
      "4                 South America   0.3744\n",
      "8                 North America   0.2896\n",
      "0    Middle East & North Africa   0.1449 \n",
      "\n",
      "AdaBoost \n",
      "                          Region Accuracy\n",
      "10                 Central Asia   0.8933\n",
      "7                Eastern Europe   0.6936\n",
      "11          Australia & Oceania   0.6857\n",
      "9                     East Asia   0.6574\n",
      "0    Middle East & North Africa   0.6049\n",
      "6   Central America & Caribbean   0.5351\n",
      "1                    South Asia   0.4983\n",
      "2                Southeast Asia   0.4941\n",
      "4                 South America   0.4746\n",
      "5                Western Europe   0.4217\n",
      "3            Sub-Saharan Africa   0.3816\n",
      "8                 North America   0.2984 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying out a few different classification algorithms to see which performs the best\n",
    "names = [\"Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(max_depth=5), \n",
    "    RandomForestClassifier(n_estimators=100, max_features=20),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier()]\n",
    "\n",
    "\n",
    "# for name, clf in zip(names, classifiers):\n",
    "#     for key, n in zip(training_y, np.arange(len(training_y))):\n",
    "#         clf.fit(training_X[key], training_y[key])\n",
    "#         results.loc[n, 'Region'] = key\n",
    "#         results.loc[n, 'Accuracy'] = round(metrics.accuracy_score(testing_y[key], clf.predict(testing_X[key])), 4)\n",
    "#     classifier_accuracies[name] = results.copy()\n",
    "\n",
    "# %store classifier_accuracies\n",
    "\n",
    "%store -r classifier_accuracies\n",
    "\n",
    "for alg in classifier_accuracies:\n",
    "    print(alg, '\\n', classifier_accuracies[alg].sort_values('Accuracy', ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors \n",
      "                          Region Accuracy\n",
      "6   Central America & Caribbean   0.7774\n",
      "3            Sub-Saharan Africa   0.7627\n",
      "9                     East Asia   0.7051\n",
      "4                 South America   0.6888\n",
      "1                    South Asia   0.6763\n",
      "0    Middle East & North Africa    0.671\n",
      "7                Eastern Europe   0.6667\n",
      "2                Southeast Asia   0.6484\n",
      "11          Australia & Oceania   0.6316\n",
      "5                Western Europe   0.6229\n",
      "8                 North America     0.47\n",
      "10                 Central Asia   0.3889 \n",
      "\n",
      "Decision Tree \n",
      "                          Region Accuracy\n",
      "6   Central America & Caribbean   0.8266\n",
      "9                     East Asia   0.7051\n",
      "7                Eastern Europe   0.6972\n",
      "3            Sub-Saharan Africa   0.6955\n",
      "4                 South America   0.6585\n",
      "1                    South Asia   0.6435\n",
      "11          Australia & Oceania   0.6316\n",
      "0    Middle East & North Africa    0.606\n",
      "2                Southeast Asia   0.5925\n",
      "5                Western Europe   0.5733\n",
      "8                 North America   0.3441\n",
      "10                 Central Asia   0.3333 \n",
      "\n",
      "Random Forest \n",
      "                          Region Accuracy\n",
      "6   Central America & Caribbean    0.838\n",
      "3            Sub-Saharan Africa   0.8204\n",
      "9                     East Asia   0.7436\n",
      "4                 South America   0.7398\n",
      "0    Middle East & North Africa   0.7382\n",
      "1                    South Asia    0.729\n",
      "7                Eastern Europe   0.7211\n",
      "2                Southeast Asia   0.7079\n",
      "5                Western Europe   0.6874\n",
      "11          Australia & Oceania   0.6842\n",
      "8                 North America   0.5929\n",
      "10                 Central Asia   0.3889 \n",
      "\n",
      "Neural Net \n",
      "                          Region Accuracy\n",
      "6   Central America & Caribbean   0.6496\n",
      "1                    South Asia   0.4966\n",
      "5                Western Europe   0.4948\n",
      "3            Sub-Saharan Africa   0.4414\n",
      "4                 South America   0.4281\n",
      "0    Middle East & North Africa   0.3217\n",
      "2                Southeast Asia   0.1815\n",
      "10                 Central Asia   0.1667\n",
      "8                 North America   0.1244\n",
      "7                Eastern Europe   0.1242\n",
      "9                     East Asia   0.0128\n",
      "11          Australia & Oceania        0 \n",
      "\n",
      "AdaBoost \n",
      "                          Region Accuracy\n",
      "6   Central America & Caribbean   0.6475\n",
      "3            Sub-Saharan Africa   0.5243\n",
      "4                 South America   0.5179\n",
      "1                    South Asia   0.4549\n",
      "2                Southeast Asia   0.4501\n",
      "0    Middle East & North Africa   0.3299\n",
      "9                     East Asia   0.2821\n",
      "7                Eastern Europe   0.2113\n",
      "5                Western Europe   0.2105\n",
      "10                 Central Asia   0.1667\n",
      "8                 North America   0.1152\n",
      "11          Australia & Oceania        0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from now on let's only use attacks with labeled groupnames, excluding 'Unknown' groups\n",
    "\n",
    "DFs_knowngnames = {}\n",
    "for reg in counts.region:\n",
    "    name = regdict[str(reg)]\n",
    "    DFs_knowngnames[name] = known_df[known_df.region==reg]\n",
    "    \n",
    "for key in DFs_knowngnames:\n",
    "    training_X[key], testing_X[key], training_y[key], testing_y[key] = train_test_split(DFs_knowngnames[key].drop('groupname', axis=1),\n",
    "                                                                                       DFs_knowngnames[key].groupname,\n",
    "                                                                                       test_size=0.3, random_state=15)\n",
    "\n",
    "# for name, clf in zip(names, classifiers):\n",
    "#     print(name)\n",
    "#     for key, n in zip(training_y, np.arange(len(training_y))):\n",
    "#         clf.fit(training_X[key], training_y[key])\n",
    "#         results.loc[n, 'Region'] = key\n",
    "#         results.loc[n, 'Accuracy'] = round(metrics.accuracy_score(testing_y[key], clf.predict(testing_X[key])), 4)\n",
    "#     print(results.sort_values('Accuracy', ascending=False))\n",
    "#     classifier_accuracies_lbld[name] = results.copy()\n",
    "\n",
    "#%store classifier_accuracies_lbld\n",
    "\n",
    "%store -r classifier_accuracies_lbld\n",
    "\n",
    "for alg in classifier_accuracies_lbld:\n",
    "    print(alg, '\\n', classifier_accuracies_lbld[alg].sort_values('Accuracy', ascending=False), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Region Accuracy\n",
      "11          Australia & Oceania   0.9474\n",
      "3            Sub-Saharan Africa   0.9317\n",
      "6   Central America & Caribbean   0.9079\n",
      "0    Middle East & North Africa   0.9061\n",
      "1                    South Asia   0.8689\n",
      "8                 North America   0.8525\n",
      "9                     East Asia   0.8205\n",
      "5                Western Europe   0.8095\n",
      "4                 South America   0.7961\n",
      "2                Southeast Asia   0.7945\n",
      "7                Eastern Europe   0.7582\n",
      "10                 Central Asia      0.5\n",
      "\n",
      "Mean Accuracy for all regions (exluding Central Asia):  0.8539\n"
     ]
    }
   ],
   "source": [
    "# create a list of most common groups in each region\n",
    "# so that we only are choosing between the 5 main groups, or else 'other'\n",
    "\n",
    "def top_or_other(gname, toplist):\n",
    "    if gname in toplist:\n",
    "        return gname\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# setting with copy warning; don't know how to fix that quickly\n",
    "top_groups = {}\n",
    "for key in countsbyreg:\n",
    "    top_groups[key] = list(countsbyreg[key]['groupname'][1:6])\n",
    "    DFs_knowngnames[key].loc[:, 'gname'] = DFs_knowngnames[key].loc[:,'groupname'] \\\n",
    "                .apply(lambda name: top_or_other(name, top_groups[key]))\n",
    "    \n",
    "\n",
    "    \n",
    "for key in DFs_knowngnames:\n",
    "    training_X[key], testing_X[key], training_y[key], testing_y[key] = train_test_split(DFs_knowngnames[key]. \\\n",
    "                                                                                    drop(['groupname','gname','region'], axis=1),\n",
    "                                                                                    DFs_knowngnames[key].gname,\n",
    "                                                                                    test_size=0.3, random_state=7)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features=20, min_samples_split=10, random_state=666)\n",
    "\n",
    "for key, n in zip(training_y, np.arange(len(training_y))):\n",
    "    clf.fit(training_X[key], training_y[key])\n",
    "    #print(training_y[key].unique())\n",
    "    results.loc[n, 'Region'] = key\n",
    "    results.loc[n, 'Accuracy'] = round(metrics.accuracy_score(testing_y[key], clf.predict(testing_X[key])), 4)\n",
    "\n",
    "\n",
    "print(results.sort_values('Accuracy', ascending=False))\n",
    "\n",
    "print('\\nMean Accuracy for all regions (exluding Central Asia): ', round(results.sort_values('Accuracy', ascending=False).Accuracy[:-1].mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Nearest Neighbors\n",
      "                         Region Accuracy\n",
      "6   Central America & Caribbean   0.8121\n",
      "3            Sub-Saharan Africa   0.7732\n",
      "4                 South America   0.6896\n",
      "0    Middle East & North Africa   0.6706\n",
      "1                    South Asia   0.6577\n",
      "7                Eastern Europe   0.6492\n",
      "11          Australia & Oceania   0.6316\n",
      "2                Southeast Asia   0.6292\n",
      "5                Western Europe   0.6165\n",
      "9                     East Asia   0.6154\n",
      "8                 North America   0.4654\n",
      "10                 Central Asia   0.3333\n",
      "\n",
      " Decision Tree\n",
      "                         Region Accuracy\n",
      "6   Central America & Caribbean   0.8209\n",
      "7                Eastern Europe   0.7015\n",
      "3            Sub-Saharan Africa   0.6951\n",
      "9                     East Asia   0.6923\n",
      "11          Australia & Oceania   0.6842\n",
      "4                 South America   0.6524\n",
      "1                    South Asia   0.6443\n",
      "0    Middle East & North Africa   0.6086\n",
      "2                Southeast Asia   0.6082\n",
      "5                Western Europe    0.565\n",
      "10                 Central Asia   0.3889\n",
      "8                 North America   0.3533\n",
      "\n",
      " Random Forest\n",
      "                         Region Accuracy\n",
      "6   Central America & Caribbean   0.8411\n",
      "3            Sub-Saharan Africa   0.8036\n",
      "4                 South America   0.7186\n",
      "7                Eastern Europe   0.7146\n",
      "0    Middle East & North Africa   0.7092\n",
      "1                    South Asia   0.6995\n",
      "9                     East Asia   0.6923\n",
      "11          Australia & Oceania   0.6842\n",
      "2                Southeast Asia   0.6827\n",
      "5                Western Europe   0.6661\n",
      "8                 North America   0.5561\n",
      "10                 Central Asia   0.3889\n",
      "\n",
      " Neural Net\n",
      "                         Region Accuracy\n",
      "6   Central America & Caribbean   0.6511\n",
      "7                Eastern Europe   0.6166\n",
      "1                    South Asia   0.5083\n",
      "3            Sub-Saharan Africa   0.4946\n",
      "5                Western Europe   0.4903\n",
      "4                 South America   0.4129\n",
      "0    Middle East & North Africa   0.3735\n",
      "2                Southeast Asia   0.1815\n",
      "8                 North America   0.1183\n",
      "10                 Central Asia   0.1111\n",
      "9                     East Asia        0\n",
      "11          Australia & Oceania        0\n"
     ]
    }
   ],
   "source": [
    "# EDIT: ADDED LATER\n",
    "# to test out the different algorithms after reducing the dataset to only 6 features\n",
    "# (['year', 'attacktype1', 'weaptype1', 'natlty1', 'targtype1', 'region'])\n",
    "names = [\"Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Neural Net\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(max_depth=5), \n",
    "    RandomForestClassifier(n_estimators=100, max_features=6),\n",
    "    MLPClassifier(alpha=1)]\n",
    "# needed to change max_features for RF\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print('\\n',name)\n",
    "    for key, n in zip(training_y, np.arange(len(training_y))):\n",
    "        clf.fit(training_X[key][['year', 'attacktype1', 'weaptype1', 'natlty1', 'targtype1', 'region']], training_y[key])\n",
    "        results.loc[n, 'Region'] = key\n",
    "        results.loc[n, 'Accuracy'] = round(metrics.accuracy_score(testing_y[key], clf.predict(testing_X[key][['year', 'attacktype1', 'weaptype1', 'natlty1', 'targtype1', 'region']])), 4)\n",
    "    print(results.sort_values('Accuracy', ascending=False).copy())\n",
    "\n",
    "# random forest still performs the best; accuracy improved for every alg, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.847 (std: 0.000)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      " \n",
      "Model with rank: 2\n",
      "Mean validation score: 0.846 (std: 0.000)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      " \n",
      "Model with rank: 3\n",
      "Mean validation score: 0.844 (std: 0.000)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 20, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      " \n",
      "Model with rank: 4\n",
      "Mean validation score: 0.844 (std: 0.000)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      " \n",
      "Model with rank: 5\n",
      "Mean validation score: 0.844 (std: 0.000)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# random forest seems to give the best results, so let's explore it further!\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=78, max_features=5, min_samples_split=10)\n",
    "\n",
    "\n",
    "# let's do a gridsearch to try and optimize our parameters; first make a dict of params to try\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 5, 20],\n",
    "              \"min_samples_split\": [3, 10],\n",
    "              \"min_samples_leaf\": [1, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# from sklearn docs:\n",
    "def report(grid_scores, n_top=5):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\" \")\n",
    "\n",
    "# split up training and testing sets: (just classifying known vs unknown here)\n",
    "X_train, X_test, y_train_bool, y_test_bool = train_test_split(df.drop(['groupname', 'is_unknown'], axis=1), df.is_unknown, \n",
    "                                                    test_size=0.3, random_state=7)\n",
    "# these training/testing dataframes are a hodgepodge of all the regions; later we'll check difference \n",
    "# between each region\n",
    "\n",
    "# commenting this out bc it takes a really long time\n",
    "# grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "# start = time()\n",
    "\n",
    "# grid_search.fit(X_train, y_train_bool)\n",
    "\n",
    "# print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "#       % (time() - start, len(grid_search.grid_scores_)))\n",
    "\n",
    "# grid_scores = grid_search.grid_scores_\n",
    "\n",
    "# %store grid_scores\n",
    "\n",
    "%store -r grid_scores\n",
    "\n",
    "report(grid_scores)\n",
    "\n",
    "# 0.847 is the max. accuracy we can get with random forest to classify labeled vs unlabeled attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy when classifying known vs. unknown:  0.8526\n",
      "Cross Val Score:  0.8465\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train_bool)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print('Random Forest accuracy when classifying known vs. unknown: ', round(metrics.accuracy_score(y_test_bool, preds), 4))\n",
    "# this is higher than the last cell bc of increased n_estimators\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train_bool)\n",
    "print('Cross Val Score: ', round(scores.mean(),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61528, 22)\n",
      "Random Forest accuracy when predicting groupname, only known groups:  0.7523\n",
      "\n",
      "Number of features in full dataset:  22\n",
      "\n",
      "             feature    weight\n",
      "13          natlty1  0.017975\n",
      "0              year  0.008357\n",
      "1            region  0.007099\n",
      "12        targtype1  0.002636\n",
      "18     weapsubtype1  0.001911\n",
      "19            nkill  0.001700\n",
      "9       attacktype1  0.001088\n",
      "5         doubtterr  0.000847\n",
      "14           nperps  0.000793\n",
      "17        weaptype1  0.000761\n",
      "6          multiple  0.000679\n",
      "15          claimed  0.000546\n",
      "4             crit3  0.000269\n",
      "20         hostages  0.000224\n",
      "7           success  0.000197\n",
      "10      attacktype2  0.000109\n",
      "8           suicide  0.000105\n",
      "16  competingclaims  0.000083\n",
      "3             crit2  0.000038\n",
      "2             crit1  0.000027\n",
      "11      attacktype3  0.000010\n",
      "21       is_unknown  0.000000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "weights = defaultdict(list)\n",
    "\n",
    "# now let's run some algorithms on only the labeled points - i.e. only predict groups where we can test our accuracy\n",
    "# our goal is to predict which groups are responsible for the unlabeled attacks\n",
    "X_train_labld, X_test_labld, y_train_labld, y_test_labld = train_test_split(known_df.drop('groupname', axis=1), known_df.groupname, \n",
    "                                                    test_size=0.3, random_state=7)\n",
    "\n",
    "print(X_train_labld.shape)\n",
    "\n",
    "newclf.fit(X_train_labld, y_train_labld)\n",
    "\n",
    "labld_preds = newclf.predict(X_test_labld)\n",
    "\n",
    "print('Random Forest accuracy when predicting groupname, only known groups: ', round(metrics.accuracy_score(y_test_labld, labld_preds), 4))\n",
    "\n",
    "# let's see how significant each feature is (going to need to get rid of some)\n",
    "for featr, wght in zip(list(X_train_labld.columns), newclf.feature_importances_):\n",
    "    weights[featr].append(wght)\n",
    "\n",
    "for feat in weights:\n",
    "    weights[feat] = sum(weights[feat])/float(len(weights))\n",
    "    \n",
    "print('\\nNumber of features in full dataset: ', len(X_train_labld.columns))\n",
    "weights = pd.DataFrame(list(weights.items()), columns=['feature', 'weight'])\n",
    "print('\\n',weights.sort_values('weight', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for trimmed dataset:  ['year', 'region', 'targtype1', 'natlty1']\n",
      "('year', 0.23043031705376724)\n",
      "('region', 0.18925527085238247)\n",
      "('targtype1', 0.096534940035296946)\n",
      "('natlty1', 0.48377947205855348)\n"
     ]
    }
   ],
   "source": [
    "# need to trim down features, obviously\n",
    "# so let's use SelectFromModel to identify which features are most important\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(newclf)\n",
    "\n",
    "sfm.fit(X_train_labld, y_train_labld)\n",
    "\n",
    "trimmedcols = list(X_train_labld.columns[sfm.get_support(indices=True)])\n",
    "\n",
    "trimmed_X = pd.DataFrame(sfm.transform(X_train_labld), columns=trimmedcols)\n",
    "trimmed_test_X = pd.DataFrame(sfm.transform(X_test_labld), columns=trimmedcols)\n",
    "\n",
    "# now making a new clf to fit smaller dataframes\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, bootstrap=True, min_samples_leaf=3, min_samples_split=3,\n",
    "                          random_state=10, n_jobs=-1)\n",
    "\n",
    "rf_clf.fit(trimmed_X, y_train_labld)\n",
    "\n",
    "print('Selected features for trimmed dataset: ', trimmedcols)\n",
    "\n",
    "for featr in zip(list(trimmed_X.columns), rf_clf.feature_importances_):\n",
    "    print(featr)\n",
    "    \n",
    "# nationality of victims has importance of almost 50% ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy with trimmed features:  0.7115\n"
     ]
    }
   ],
   "source": [
    "# let's see how the model performs on the trimmed data\n",
    "newpreds = rf_clf.predict(trimmed_test_X)\n",
    "\n",
    "print('Random Forest accuracy with trimmed features: ', round(metrics.accuracy_score(y_test_labld, newpreds), 4))\n",
    "\n",
    "# the accuracy only decreased by ~4%, but using 4 features instead of 22! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Region Accuracy Num Features\n",
      "3            Sub-Saharan Africa   0.9188            5\n",
      "11          Australia & Oceania   0.8947            6\n",
      "0    Middle East & North Africa   0.8906            5\n",
      "6   Central America & Caribbean   0.8887            4\n",
      "1                    South Asia   0.8474            5\n",
      "8                 North America   0.8264            5\n",
      "9                     East Asia   0.8205            9\n",
      "5                Western Europe    0.794            4\n",
      "2                Southeast Asia   0.7644            6\n",
      "4                 South America   0.7567            4\n",
      "7                Eastern Europe   0.7473            5\n",
      "10                 Central Asia   0.2778            9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# now let's select important features for each region\n",
    "clf_regions = RandomForestClassifier(n_estimators=200, random_state=15)\n",
    "\n",
    "newsfm = SelectFromModel(clf_regions)\n",
    "\n",
    "results_byregion = pd.DataFrame(columns=['Region', 'Accuracy', 'Num Features'])\n",
    "\n",
    "for key, n in zip(training_y, np.arange(len(training_y))):\n",
    "    newsfm.fit(training_X[key], training_y[key])\n",
    "    cols = list(training_X[key].columns[newsfm.get_support(indices=True)])\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=15, n_jobs=-1)\n",
    "    Xtrain = pd.DataFrame(newsfm.transform(training_X[key]), columns=cols)\n",
    "    Xtest = pd.DataFrame(newsfm.transform(testing_X[key]), columns=cols)\n",
    "    clf.fit(Xtrain, training_y[key])\n",
    "    results_byregion.loc[n, 'Region'] = key\n",
    "    results_byregion.loc[n, 'Accuracy'] = round(metrics.accuracy_score(testing_y[key], clf.predict(Xtest)), 4)\n",
    "    results_byregion.loc[n, 'Num Features'] = int(len(cols))\n",
    "\n",
    "print(results_byregion.sort_values('Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how could we improve this further? what are the limitations?\n",
    "\n",
    "# it was relatively arbitrary that I decided to only consider groups with 5+ attacks; could try altering this \n",
    "# to see effects on accuracy\n",
    "# could try: keep all incidents in the data, but groups with < n attacks go into an 'Other' label\n",
    "\n",
    "# why is the accuracy in some regions so low? for central/east Asia and Australia, much less data \n",
    "# and a very high % of unknown attacks\n",
    "\n",
    "# the goal is to predict 'Unknown' attacks, but can't check accuracy on the unlabeled attacks "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
